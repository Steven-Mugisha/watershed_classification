{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "load_dotenv()\n",
    "directory = os.getenv(\"path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<-- clustering done -->\n",
      "<-- clustering done -->\n",
      "<-- clustering done -->\n"
     ]
    }
   ],
   "source": [
    "# NOTE: The save csv the values are the indices of the stations in the original dataset that are exmplars\n",
    "# NOTE: starting from 0 to n-1 where n is the number of stations in the dataset.\n",
    "\n",
    "model = AffinityPropagation()\n",
    "\n",
    "# Clustering with AP.\n",
    "def clustering(dir, output_dir, model, dataset):\n",
    "    paths = os.listdir(dir)\n",
    "    files = sorted([file for file in paths if file.endswith(\".csv\")])\n",
    "\n",
    "    ap_res = {}\n",
    "    for file in files:\n",
    "        df = pd.read_csv(os.path.join(dir, file))\n",
    "\n",
    "        if \"Unnamed: 0\" in df.columns:\n",
    "            df.drop(df.columns[0], axis=1, inplace=True)\n",
    "            df.set_index(df.columns[0], inplace=True)\n",
    "\n",
    "        else:\n",
    "            df.set_index(df.columns[0], inplace=True)\n",
    "\n",
    "        df = df.fillna(df.median())\n",
    "\n",
    "        # AP clustering.\n",
    "        model.fit(df)\n",
    "        stations_index = list(model.cluster_centers_indices_)\n",
    "\n",
    "\n",
    "        indices= {}\n",
    "        for index, station in enumerate(list(stations_index)):\n",
    "            indices[index] = station\n",
    "\n",
    "        # assingning cluster labels to the stations\n",
    "        labels = model.labels_\n",
    "        ap_labels = [indices[station] for station in labels]\n",
    "\n",
    "        ap_res[file.split(\"/\")[-1].split(\".\")[0]] = list(ap_labels)\n",
    "        result = pd.DataFrame(ap_res).set_index(df.index)\n",
    "    \n",
    "\n",
    "    try:\n",
    "        result.to_csv(os.path.join(output_dir, f'{dataset}.csv'), index=True)\n",
    "        print(f'<-- clustering done -->')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "    return result\n",
    "\n",
    "# NOTE: Clustering with AP.\n",
    "datasets = [\"func\", \"func_climate\", \"all_attributes\"]\n",
    "\n",
    "for dataset in datasets:\n",
    "    dir = os.path.join(directory, \"computed_data/pca_results\", dataset)\n",
    "    outputdir = os.path.join(directory, \"computed_data/ap_results\")\n",
    "    res = clustering(dir, outputdir, model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the number of clusters\n",
    "dir = os.path.join(directory, 'computed_data/ap_results')\n",
    "paths = os.listdir(dir)\n",
    "files = sorted([file for file in paths if file.endswith(\".csv\")])\n",
    "\n",
    "ap_results = {}\n",
    "for file in files:\n",
    "    df = pd.read_csv(os.path.join(dir, file))\n",
    "    for col in df.columns:\n",
    "        if col == 'station_id':\n",
    "            continue\n",
    "        ap_results[col] = df[col].nunique()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
