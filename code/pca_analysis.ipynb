{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pca import PCA_Analysis\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "# load .env file and pca class\n",
    "load_dotenv()\n",
    "directory = os.getenv(\"path\")\n",
    "output_dir = os.getenv(\"output_dir\")\n",
    "pca = PCA_Analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting top attributes from computed pca\n",
    "def select_top_attr(all_top_attr, attribute) -> list:\n",
    "    selected_attr = []\n",
    "    top_attr = all_top_attr[attribute]\n",
    "    attrs_list = list(top_attr.values())\n",
    "\n",
    "    for i in range(4):\n",
    "        selected_attr.append(attrs_list[0][i])\n",
    "    for i in range(2):\n",
    "        selected_attr.append(attrs_list[1][i])\n",
    "    return list(set(selected_attr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "structural attributes (Time-invariant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PC1': ['std_topsoil_sand',\n",
       "  'median_topsoil_sand',\n",
       "  'std_topsoil_silt',\n",
       "  'median_topsoil_silt',\n",
       "  'std_topsoil_clay'],\n",
       " 'PC2': ['std_topsoil_clay',\n",
       "  'median_topsoil_sand',\n",
       "  'median_soil_depth',\n",
       "  'std_topsoil_sand',\n",
       "  'std_topsoil_silt']}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def structural_pca() -> dict:\n",
    "    struct_path = os.path.join(directory, \"data\",\"raw_datasets\", \"structural_attributes\", \"140_TI_variables\")\n",
    "    stations_list = pd.read_csv(os.path.join(directory,  \"data\",\"raw_datasets\", \"structural_attributes\", \"stations_list.csv\")).stations.tolist()\n",
    "\n",
    "    struct_files = os.listdir(struct_path)\n",
    "    struct_files = [file for file in struct_files if file.endswith(\".csv\")]\n",
    "\n",
    "    all_top_load_dfs, all_top_attr = [], {}\n",
    "\n",
    "    for file in struct_files:\n",
    "        attr_type = file.split(\"_\")[1].split(\".\")[0]\n",
    "        input_struct_data = pd.read_csv(os.path.join(struct_path, file))\n",
    "\n",
    "        input_struct_data = input_struct_data[input_struct_data[\"station_id\"].isin(stations_list)]\n",
    "\n",
    "        struct_data = pd.concat([input_struct_data[\"station_id\"], input_struct_data.iloc[:, 4:]], axis = 1)\n",
    "        struct_data = struct_data.set_index(\"station_id\")\n",
    "\n",
    "        loadings = pca.loadings(struct_data)\n",
    "\n",
    "        explained_var = pca.explained_variance(struct_data)\n",
    "        pc1_val = round(explained_var[\"Explained Variance\"].iloc[1],2)\n",
    "        pc2_val = round(explained_var[\"Explained Variance\"].iloc[2],2)\n",
    "\n",
    "        top_attr = pca.top_attributes(loadings, 5)\n",
    "        all_top_attr[attr_type] = top_attr\n",
    "        new_keys = {'PC1': f'{attr_type}_PC1_{pc1_val}', 'PC2': f'{attr_type}_PC2_{pc2_val}'}\n",
    "        renamed_top_attr = {new_keys[key]: value for key, value in top_attr.items()}\n",
    "        top_load_df = pd.DataFrame(renamed_top_attr)\n",
    "        all_top_load_dfs.append(top_load_df)\n",
    "    # return  pd.concat(all_top_load_dfs, axis = 1)\n",
    "    # out_put_df.to_csv(os.path.join(directory, \"pca_results\", \"TI_top_attributes.csv\"), index=False)\n",
    "    return all_top_attr\n",
    "\n",
    "structural_pca()[\"soil\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>std_topsoil_silt</th>\n",
       "      <th>std_topsoil_clay</th>\n",
       "      <th>std_topsoil_sand</th>\n",
       "      <th>median_topsoil_silt</th>\n",
       "      <th>median_topsoil_sand</th>\n",
       "      <th>%cropland</th>\n",
       "      <th>%forest</th>\n",
       "      <th>%wetland</th>\n",
       "      <th>%water</th>\n",
       "      <th>%grassland</th>\n",
       "      <th>std_elevation</th>\n",
       "      <th>max_elevation</th>\n",
       "      <th>range_elevation</th>\n",
       "      <th>median_elevation</th>\n",
       "      <th>mean_elevation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.170080</td>\n",
       "      <td>8.705036</td>\n",
       "      <td>15.565180</td>\n",
       "      <td>50</td>\n",
       "      <td>26</td>\n",
       "      <td>68.998906</td>\n",
       "      <td>15.832885</td>\n",
       "      <td>0.664702</td>\n",
       "      <td>1.392658</td>\n",
       "      <td>0.437804</td>\n",
       "      <td>62.273206</td>\n",
       "      <td>539</td>\n",
       "      <td>280</td>\n",
       "      <td>411</td>\n",
       "      <td>408.804259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.104138</td>\n",
       "      <td>6.927044</td>\n",
       "      <td>12.031182</td>\n",
       "      <td>50</td>\n",
       "      <td>17</td>\n",
       "      <td>84.426076</td>\n",
       "      <td>10.223111</td>\n",
       "      <td>0.260911</td>\n",
       "      <td>0.057743</td>\n",
       "      <td>0.280158</td>\n",
       "      <td>18.732971</td>\n",
       "      <td>508</td>\n",
       "      <td>105</td>\n",
       "      <td>462</td>\n",
       "      <td>456.647797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.926256</td>\n",
       "      <td>9.597431</td>\n",
       "      <td>13.566371</td>\n",
       "      <td>50</td>\n",
       "      <td>17</td>\n",
       "      <td>80.612989</td>\n",
       "      <td>11.655630</td>\n",
       "      <td>0.249661</td>\n",
       "      <td>0.549254</td>\n",
       "      <td>0.220120</td>\n",
       "      <td>36.743025</td>\n",
       "      <td>441</td>\n",
       "      <td>194</td>\n",
       "      <td>363</td>\n",
       "      <td>354.024238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.847713</td>\n",
       "      <td>8.844053</td>\n",
       "      <td>13.724722</td>\n",
       "      <td>50</td>\n",
       "      <td>26</td>\n",
       "      <td>74.802225</td>\n",
       "      <td>15.943270</td>\n",
       "      <td>1.717514</td>\n",
       "      <td>2.085602</td>\n",
       "      <td>0.799634</td>\n",
       "      <td>14.320739</td>\n",
       "      <td>539</td>\n",
       "      <td>102</td>\n",
       "      <td>487</td>\n",
       "      <td>490.430777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.991387</td>\n",
       "      <td>4.134774</td>\n",
       "      <td>7.125058</td>\n",
       "      <td>36</td>\n",
       "      <td>50</td>\n",
       "      <td>61.204512</td>\n",
       "      <td>26.616951</td>\n",
       "      <td>0.477796</td>\n",
       "      <td>0.867342</td>\n",
       "      <td>0.340075</td>\n",
       "      <td>36.667031</td>\n",
       "      <td>506</td>\n",
       "      <td>211</td>\n",
       "      <td>384</td>\n",
       "      <td>385.497491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2.715522</td>\n",
       "      <td>5.111560</td>\n",
       "      <td>3.409538</td>\n",
       "      <td>56</td>\n",
       "      <td>31</td>\n",
       "      <td>20.926085</td>\n",
       "      <td>62.425168</td>\n",
       "      <td>4.021247</td>\n",
       "      <td>0.341540</td>\n",
       "      <td>0.744922</td>\n",
       "      <td>93.604877</td>\n",
       "      <td>598</td>\n",
       "      <td>415</td>\n",
       "      <td>404</td>\n",
       "      <td>391.824850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>3.155841</td>\n",
       "      <td>6.100140</td>\n",
       "      <td>4.228345</td>\n",
       "      <td>51</td>\n",
       "      <td>31</td>\n",
       "      <td>38.923298</td>\n",
       "      <td>49.756332</td>\n",
       "      <td>4.273898</td>\n",
       "      <td>0.862061</td>\n",
       "      <td>0.727606</td>\n",
       "      <td>70.777109</td>\n",
       "      <td>630</td>\n",
       "      <td>338</td>\n",
       "      <td>473</td>\n",
       "      <td>465.915367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>3.521046</td>\n",
       "      <td>4.893305</td>\n",
       "      <td>4.476393</td>\n",
       "      <td>51</td>\n",
       "      <td>31</td>\n",
       "      <td>43.565460</td>\n",
       "      <td>39.755651</td>\n",
       "      <td>8.006014</td>\n",
       "      <td>0.989909</td>\n",
       "      <td>0.727843</td>\n",
       "      <td>95.489068</td>\n",
       "      <td>630</td>\n",
       "      <td>365</td>\n",
       "      <td>407</td>\n",
       "      <td>404.317641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>7.280444</td>\n",
       "      <td>3.999675</td>\n",
       "      <td>7.571920</td>\n",
       "      <td>51</td>\n",
       "      <td>23</td>\n",
       "      <td>45.486890</td>\n",
       "      <td>28.492574</td>\n",
       "      <td>17.236124</td>\n",
       "      <td>0.699812</td>\n",
       "      <td>0.528546</td>\n",
       "      <td>106.358210</td>\n",
       "      <td>630</td>\n",
       "      <td>455</td>\n",
       "      <td>278</td>\n",
       "      <td>314.382768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>2.129150</td>\n",
       "      <td>1.064575</td>\n",
       "      <td>3.193725</td>\n",
       "      <td>51</td>\n",
       "      <td>23</td>\n",
       "      <td>29.530264</td>\n",
       "      <td>28.396166</td>\n",
       "      <td>19.773589</td>\n",
       "      <td>0.893470</td>\n",
       "      <td>0.930647</td>\n",
       "      <td>46.275710</td>\n",
       "      <td>442</td>\n",
       "      <td>265</td>\n",
       "      <td>257</td>\n",
       "      <td>265.739443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     std_topsoil_silt  std_topsoil_clay  std_topsoil_sand  \\\n",
       "0            8.170080          8.705036         15.565180   \n",
       "1            5.104138          6.927044         12.031182   \n",
       "2            5.926256          9.597431         13.566371   \n",
       "3            7.847713          8.844053         13.724722   \n",
       "4            2.991387          4.134774          7.125058   \n",
       "..                ...               ...               ...   \n",
       "128          2.715522          5.111560          3.409538   \n",
       "129          3.155841          6.100140          4.228345   \n",
       "130          3.521046          4.893305          4.476393   \n",
       "131          7.280444          3.999675          7.571920   \n",
       "132          2.129150          1.064575          3.193725   \n",
       "\n",
       "     median_topsoil_silt  median_topsoil_sand  %cropland    %forest  \\\n",
       "0                     50                   26  68.998906  15.832885   \n",
       "1                     50                   17  84.426076  10.223111   \n",
       "2                     50                   17  80.612989  11.655630   \n",
       "3                     50                   26  74.802225  15.943270   \n",
       "4                     36                   50  61.204512  26.616951   \n",
       "..                   ...                  ...        ...        ...   \n",
       "128                   56                   31  20.926085  62.425168   \n",
       "129                   51                   31  38.923298  49.756332   \n",
       "130                   51                   31  43.565460  39.755651   \n",
       "131                   51                   23  45.486890  28.492574   \n",
       "132                   51                   23  29.530264  28.396166   \n",
       "\n",
       "      %wetland    %water  %grassland  std_elevation  max_elevation  \\\n",
       "0     0.664702  1.392658    0.437804      62.273206            539   \n",
       "1     0.260911  0.057743    0.280158      18.732971            508   \n",
       "2     0.249661  0.549254    0.220120      36.743025            441   \n",
       "3     1.717514  2.085602    0.799634      14.320739            539   \n",
       "4     0.477796  0.867342    0.340075      36.667031            506   \n",
       "..         ...       ...         ...            ...            ...   \n",
       "128   4.021247  0.341540    0.744922      93.604877            598   \n",
       "129   4.273898  0.862061    0.727606      70.777109            630   \n",
       "130   8.006014  0.989909    0.727843      95.489068            630   \n",
       "131  17.236124  0.699812    0.528546     106.358210            630   \n",
       "132  19.773589  0.893470    0.930647      46.275710            442   \n",
       "\n",
       "     range_elevation  median_elevation  mean_elevation  \n",
       "0                280               411      408.804259  \n",
       "1                105               462      456.647797  \n",
       "2                194               363      354.024238  \n",
       "3                102               487      490.430777  \n",
       "4                211               384      385.497491  \n",
       "..               ...               ...             ...  \n",
       "128              415               404      391.824850  \n",
       "129              338               473      465.915367  \n",
       "130              365               407      404.317641  \n",
       "131              455               278      314.382768  \n",
       "132              265               257      265.739443  \n",
       "\n",
       "[133 rows x 15 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate new datasets with selected attributes\n",
    "def generate_struct_df() -> pd.DataFrame:\n",
    "    attr_collection = []\n",
    "    struct_pca = structural_pca()\n",
    "    for key in struct_pca.keys():\n",
    "        attributes = select_top_attr(struct_pca, key)\n",
    "        path = os.path.join(\n",
    "            directory,\n",
    "            \"data\",\n",
    "            \"raw_datasets\",\n",
    "            \"structural_attributes\",\n",
    "            \"140_TI_variables\",\n",
    "            f\"leb_{key}.csv\",\n",
    "        )\n",
    "        stations_list = pd.read_csv(\n",
    "            os.path.join(\n",
    "                directory,\n",
    "                \"data\",\n",
    "                \"raw_datasets\",\n",
    "                \"structural_attributes\",\n",
    "                \"stations_list.csv\",\n",
    "            )\n",
    "        ).stations.tolist()\n",
    "        # input_struct_data = input_struct_data[input_struct_data[\"station_id\"].isin(stations_list)]\n",
    "\n",
    "        att_file = pd.read_csv(path)\n",
    "        _133_stations_df = att_file[att_file[\"station_id\"].isin(stations_list)]\n",
    "        _133_stations_df = _133_stations_df[attributes]\n",
    "        attr_collection.append(_133_stations_df)\n",
    "\n",
    "    return pd.concat(attr_collection, axis=1).reset_index(drop=True)\n",
    "\n",
    "generate_struct_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "crop inventories (Time-variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'crop_inventory_2012': {'PC1': ['grapes2012', 'springwheat2012', 'oats2012', 'tomatoes2012', 'sod2012'], 'PC2': ['soyabeans2012', 'winterwheat2012', 'tomatoes2012', 'corn2012', 'springwheat2012']}, 'crop_inventory_2013': {'PC1': ['grapes2013', 'springwheat2013', 'tomatoes2013', 'fallow2013', 'winterwheat2013'], 'PC2': ['soyabeans2013', 'corn2013', 'winterwheat2013', 'fallow2013', 'tomatoes2013']}, 'crop_inventory_2011': {'PC1': ['oats2011', 'springwheat2011', 'grapes2011', 'tomatoes2011', 'peas2011'], 'PC2': ['soyabeans2011', 'winterwheat2011', 'corn2011', 'tomatoes2011', 'fallow2011']}, 'crop_inventory_2014': {'PC1': ['springwheat2014', 'grapes2014', 'winterwheat2014', 'tomatoes2014', 'potatoes2014'], 'PC2': ['soyabeans2014', 'corn2014', 'fallow2014', 'winterwheat2014', 'peas2014']}, 'crop_inventory_2015': {'PC1': ['tomatoes2015', 'grapes2015', 'springwheat2015', 'potatoes2015', 'winterwheat2015'], 'PC2': ['potatoes2015', 'winterwheat2015', 'grapes2015', 'soyabeans2015', 'canola2015']}, 'crop_inventory_2017': {'PC1': ['winterwheat2017', 'corn2017', 'fallow2017', 'soyabeans2017', 'grapes2017'], 'PC2': ['tomatoes2017', 'canola2017', 'soyabeans2017', 'corn2017', 'oats2017']}, 'crop_inventory_2016': {'PC1': ['springwheat2016', 'canola2016', 'oats2016', 'potatoes2016', 'winterwheat2016'], 'PC2': ['corn2016', 'winterwheat2016', 'soyabeans2016', 'fallow2016', 'grapes2016']}, 'crop_inventory_2018': {'PC1': ['winterwheat2018', 'corn2018', 'oats2018', 'springwheat2018', 'beans2018'], 'PC2': ['canola2018', 'oats2018', 'springwheat2018', 'corn2018', 'soyabeans2018']}, 'crop_inventory_2019': {'PC1': ['winterwheat2019', 'corn2019', 'springwheat2019', 'soyabeans2019', 'canola2019'], 'PC2': ['canola2019', 'oats2019', 'soyabeans2019', 'springwheat2019', 'corn2019']}, 'crop_inventory_2020': {'PC1': ['springwheat2020', 'canola2020', 'oats2020', 'potatoes2020', 'winterwheat2020'], 'PC2': ['corn2020', 'winterwheat2020', 'tomatoes2020', 'fallow2020', 'beans2020']}}\n"
     ]
    }
   ],
   "source": [
    "def crop_pca() -> dict:\n",
    "    crops_path = os.path.join(directory, \"data\", \"raw_datasets\", \"structural_attributes\", \"crop_inventories\")\n",
    "\n",
    "    crop_inventories_files = glob.glob(f\"{crops_path}/*.csv\")\n",
    "\n",
    "    all_crop_top_load_dfs, all_top_attr  = [], {}\n",
    "\n",
    "    for path in crop_inventories_files:\n",
    "        crop_yr_df = pd.read_csv(path)\n",
    "        crop_yr_df = crop_yr_df.set_index(crop_yr_df.columns[0])\n",
    "\n",
    "        # crop pca analysis\n",
    "        # pca_df = pca.pca_analysis(crop_yr_df)\n",
    "        loadings = pca.loadings(crop_yr_df)\n",
    "\n",
    "        explained_var = pca.explained_variance(crop_yr_df)\n",
    "        pc1_val = round(explained_var[\"Explained Variance\"].iloc[1],2)\n",
    "        pc2_val = round(explained_var[\"Explained Variance\"].iloc[2],2)\n",
    "\n",
    "        top_attr = pca.top_attributes(loadings, 5)\n",
    "        all_top_attr[path.split(\"/\")[-1].split(\".\")[0]] = top_attr\n",
    "        new_keys = {'PC1': f'{path.split(\"/\")[-1].split(\".\")[0]}_PC1_{pc1_val}', 'PC2': f'{path.split(\"/\")[-1].split(\".\")[0]}_PC2_{pc2_val}'}\n",
    "        renamed_top_attr = {new_keys[key]: value for key, value in top_attr.items()}\n",
    "        top_load_df = pd.DataFrame(renamed_top_attr)\n",
    "        all_crop_top_load_dfs.append(top_load_df)\n",
    "\n",
    "    # crop_out_put_df = pd.concat(all_crop_top_load_dfs, axis = 1)\n",
    "    # crop_out_put_df = crop_out_put_df.reindex(sorted(crop_out_put_df.columns), axis=1)\n",
    "    # crop_out_put_df.to_csv(os.path.join(directory, \"pca_results\", \"crop_top_attributes.csv\"), index=False)\n",
    "\n",
    "    return all_top_attr\n",
    "\n",
    "print(crop_pca())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining TI (soil, lucl, terrain) and TV (crop inventory) datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to select top attributes for year variant attributes.\n",
    "def selectTopAtttributesForYear(datatype: dict) -> list:\n",
    "    pca_selected_attr = []\n",
    "    for _,val in datatype.items():\n",
    "        yearTopAttributes, topAttributes = [], []\n",
    "        for _,v in val.items():\n",
    "            yearTopAttributes.append(v)\n",
    "\n",
    "        for i in range(4):\n",
    "            topAttributes.append(yearTopAttributes[0][i])\n",
    "        for i in range(2):\n",
    "            topAttributes.append(yearTopAttributes[1][i])\n",
    "\n",
    "        pca_selected_attr.append(list(set(topAttributes)))\n",
    "\n",
    "    # selected_attr = []\n",
    "    counter = {}\n",
    "    for arr_attrs in pca_selected_attr:\n",
    "        for attr in arr_attrs:\n",
    "            attr = attr.split(\"2\")[0]\n",
    "            if attr in counter:\n",
    "                counter[attr] += 1\n",
    "            else:\n",
    "                counter[attr] = 1\n",
    "\n",
    "    count, selected_attr = 0, set()\n",
    "    count_values = sorted(list(counter.values()), reverse=True)\n",
    "    # print(\"counter_values\", count_values)\n",
    "    lookup_counter = min(count_values[:5])\n",
    "\n",
    "\n",
    "    for key, value in counter.items():\n",
    "        if value >= lookup_counter:\n",
    "            count += 1\n",
    "            selected_attr.add(key)\n",
    "\n",
    "    return list(selected_attr)\n",
    "\n",
    "# testing:\n",
    "# crops_data = crop_pca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>std_topsoil_silt</th>\n",
       "      <th>std_topsoil_clay</th>\n",
       "      <th>std_topsoil_sand</th>\n",
       "      <th>median_topsoil_silt</th>\n",
       "      <th>median_topsoil_sand</th>\n",
       "      <th>%cropland</th>\n",
       "      <th>%forest</th>\n",
       "      <th>%wetland</th>\n",
       "      <th>%water</th>\n",
       "      <th>%grassland</th>\n",
       "      <th>...</th>\n",
       "      <th>max_elevation</th>\n",
       "      <th>range_elevation</th>\n",
       "      <th>median_elevation</th>\n",
       "      <th>mean_elevation</th>\n",
       "      <th>corn</th>\n",
       "      <th>tomatoes</th>\n",
       "      <th>oats</th>\n",
       "      <th>soyabeans</th>\n",
       "      <th>springwheat</th>\n",
       "      <th>winterwheat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.170080</td>\n",
       "      <td>8.705036</td>\n",
       "      <td>15.565180</td>\n",
       "      <td>50</td>\n",
       "      <td>26</td>\n",
       "      <td>68.998906</td>\n",
       "      <td>15.832885</td>\n",
       "      <td>0.664702</td>\n",
       "      <td>1.392658</td>\n",
       "      <td>0.437804</td>\n",
       "      <td>...</td>\n",
       "      <td>539</td>\n",
       "      <td>280</td>\n",
       "      <td>411</td>\n",
       "      <td>408.804259</td>\n",
       "      <td>18.061561</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.655077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.104138</td>\n",
       "      <td>6.927044</td>\n",
       "      <td>12.031182</td>\n",
       "      <td>50</td>\n",
       "      <td>17</td>\n",
       "      <td>84.426076</td>\n",
       "      <td>10.223111</td>\n",
       "      <td>0.260911</td>\n",
       "      <td>0.057743</td>\n",
       "      <td>0.280158</td>\n",
       "      <td>...</td>\n",
       "      <td>508</td>\n",
       "      <td>105</td>\n",
       "      <td>462</td>\n",
       "      <td>456.647797</td>\n",
       "      <td>23.698112</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.446032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.926256</td>\n",
       "      <td>9.597431</td>\n",
       "      <td>13.566371</td>\n",
       "      <td>50</td>\n",
       "      <td>17</td>\n",
       "      <td>80.612989</td>\n",
       "      <td>11.655630</td>\n",
       "      <td>0.249661</td>\n",
       "      <td>0.549254</td>\n",
       "      <td>0.220120</td>\n",
       "      <td>...</td>\n",
       "      <td>441</td>\n",
       "      <td>194</td>\n",
       "      <td>363</td>\n",
       "      <td>354.024238</td>\n",
       "      <td>25.089803</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.327990</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.847713</td>\n",
       "      <td>8.844053</td>\n",
       "      <td>13.724722</td>\n",
       "      <td>50</td>\n",
       "      <td>26</td>\n",
       "      <td>74.802225</td>\n",
       "      <td>15.943270</td>\n",
       "      <td>1.717514</td>\n",
       "      <td>2.085602</td>\n",
       "      <td>0.799634</td>\n",
       "      <td>...</td>\n",
       "      <td>539</td>\n",
       "      <td>102</td>\n",
       "      <td>487</td>\n",
       "      <td>490.430777</td>\n",
       "      <td>10.929124</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.864170</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.991387</td>\n",
       "      <td>4.134774</td>\n",
       "      <td>7.125058</td>\n",
       "      <td>36</td>\n",
       "      <td>50</td>\n",
       "      <td>61.204512</td>\n",
       "      <td>26.616951</td>\n",
       "      <td>0.477796</td>\n",
       "      <td>0.867342</td>\n",
       "      <td>0.340075</td>\n",
       "      <td>...</td>\n",
       "      <td>506</td>\n",
       "      <td>211</td>\n",
       "      <td>384</td>\n",
       "      <td>385.497491</td>\n",
       "      <td>12.710850</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.783461</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2.715522</td>\n",
       "      <td>5.111560</td>\n",
       "      <td>3.409538</td>\n",
       "      <td>56</td>\n",
       "      <td>31</td>\n",
       "      <td>20.926085</td>\n",
       "      <td>62.425168</td>\n",
       "      <td>4.021247</td>\n",
       "      <td>0.341540</td>\n",
       "      <td>0.744922</td>\n",
       "      <td>...</td>\n",
       "      <td>598</td>\n",
       "      <td>415</td>\n",
       "      <td>404</td>\n",
       "      <td>391.824850</td>\n",
       "      <td>1.674956</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>0.150118</td>\n",
       "      <td>0.327531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.121308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>3.155841</td>\n",
       "      <td>6.100140</td>\n",
       "      <td>4.228345</td>\n",
       "      <td>51</td>\n",
       "      <td>31</td>\n",
       "      <td>38.923298</td>\n",
       "      <td>49.756332</td>\n",
       "      <td>4.273898</td>\n",
       "      <td>0.862061</td>\n",
       "      <td>0.727606</td>\n",
       "      <td>...</td>\n",
       "      <td>630</td>\n",
       "      <td>338</td>\n",
       "      <td>473</td>\n",
       "      <td>465.915367</td>\n",
       "      <td>15.219172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.421673</td>\n",
       "      <td>0.407922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>3.521046</td>\n",
       "      <td>4.893305</td>\n",
       "      <td>4.476393</td>\n",
       "      <td>51</td>\n",
       "      <td>31</td>\n",
       "      <td>43.565460</td>\n",
       "      <td>39.755651</td>\n",
       "      <td>8.006014</td>\n",
       "      <td>0.989909</td>\n",
       "      <td>0.727843</td>\n",
       "      <td>...</td>\n",
       "      <td>630</td>\n",
       "      <td>365</td>\n",
       "      <td>407</td>\n",
       "      <td>404.317641</td>\n",
       "      <td>15.998103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.427356</td>\n",
       "      <td>0.697591</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.484688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>7.280444</td>\n",
       "      <td>3.999675</td>\n",
       "      <td>7.571920</td>\n",
       "      <td>51</td>\n",
       "      <td>23</td>\n",
       "      <td>45.486890</td>\n",
       "      <td>28.492574</td>\n",
       "      <td>17.236124</td>\n",
       "      <td>0.699812</td>\n",
       "      <td>0.528546</td>\n",
       "      <td>...</td>\n",
       "      <td>630</td>\n",
       "      <td>455</td>\n",
       "      <td>278</td>\n",
       "      <td>314.382768</td>\n",
       "      <td>14.749155</td>\n",
       "      <td>0.001077</td>\n",
       "      <td>0.414476</td>\n",
       "      <td>2.293613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.791003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>2.129150</td>\n",
       "      <td>1.064575</td>\n",
       "      <td>3.193725</td>\n",
       "      <td>51</td>\n",
       "      <td>23</td>\n",
       "      <td>29.530264</td>\n",
       "      <td>28.396166</td>\n",
       "      <td>19.773589</td>\n",
       "      <td>0.893470</td>\n",
       "      <td>0.930647</td>\n",
       "      <td>...</td>\n",
       "      <td>442</td>\n",
       "      <td>265</td>\n",
       "      <td>257</td>\n",
       "      <td>265.739443</td>\n",
       "      <td>5.549383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.381406</td>\n",
       "      <td>1.205300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.421807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     std_topsoil_silt  std_topsoil_clay  std_topsoil_sand  \\\n",
       "0            8.170080          8.705036         15.565180   \n",
       "1            5.104138          6.927044         12.031182   \n",
       "2            5.926256          9.597431         13.566371   \n",
       "3            7.847713          8.844053         13.724722   \n",
       "4            2.991387          4.134774          7.125058   \n",
       "..                ...               ...               ...   \n",
       "128          2.715522          5.111560          3.409538   \n",
       "129          3.155841          6.100140          4.228345   \n",
       "130          3.521046          4.893305          4.476393   \n",
       "131          7.280444          3.999675          7.571920   \n",
       "132          2.129150          1.064575          3.193725   \n",
       "\n",
       "     median_topsoil_silt  median_topsoil_sand  %cropland    %forest  \\\n",
       "0                     50                   26  68.998906  15.832885   \n",
       "1                     50                   17  84.426076  10.223111   \n",
       "2                     50                   17  80.612989  11.655630   \n",
       "3                     50                   26  74.802225  15.943270   \n",
       "4                     36                   50  61.204512  26.616951   \n",
       "..                   ...                  ...        ...        ...   \n",
       "128                   56                   31  20.926085  62.425168   \n",
       "129                   51                   31  38.923298  49.756332   \n",
       "130                   51                   31  43.565460  39.755651   \n",
       "131                   51                   23  45.486890  28.492574   \n",
       "132                   51                   23  29.530264  28.396166   \n",
       "\n",
       "      %wetland    %water  %grassland  ...  max_elevation  range_elevation  \\\n",
       "0     0.664702  1.392658    0.437804  ...            539              280   \n",
       "1     0.260911  0.057743    0.280158  ...            508              105   \n",
       "2     0.249661  0.549254    0.220120  ...            441              194   \n",
       "3     1.717514  2.085602    0.799634  ...            539              102   \n",
       "4     0.477796  0.867342    0.340075  ...            506              211   \n",
       "..         ...       ...         ...  ...            ...              ...   \n",
       "128   4.021247  0.341540    0.744922  ...            598              415   \n",
       "129   4.273898  0.862061    0.727606  ...            630              338   \n",
       "130   8.006014  0.989909    0.727843  ...            630              365   \n",
       "131  17.236124  0.699812    0.528546  ...            630              455   \n",
       "132  19.773589  0.893470    0.930647  ...            442              265   \n",
       "\n",
       "     median_elevation  mean_elevation       corn  tomatoes      oats  \\\n",
       "0                 411      408.804259  18.061561  0.000000  0.000000   \n",
       "1                 462      456.647797  23.698112  0.000000  0.000000   \n",
       "2                 363      354.024238  25.089803  0.000000  0.000000   \n",
       "3                 487      490.430777  10.929124  0.000000  0.000000   \n",
       "4                 384      385.497491  12.710850  0.000000  0.000000   \n",
       "..                ...             ...        ...       ...       ...   \n",
       "128               404      391.824850   1.674956  0.000607  0.150118   \n",
       "129               473      465.915367  15.219172  0.000000  0.421673   \n",
       "130               407      404.317641  15.998103  0.000000  0.427356   \n",
       "131               278      314.382768  14.749155  0.001077  0.414476   \n",
       "132               257      265.739443   5.549383  0.000000  0.381406   \n",
       "\n",
       "     soyabeans  springwheat  winterwheat  \n",
       "0    10.655077          0.0     0.000000  \n",
       "1    16.446032          0.0     0.000000  \n",
       "2    16.327990          0.0     0.000000  \n",
       "3     7.864170          0.0     0.000000  \n",
       "4    10.783461          0.0     0.000000  \n",
       "..         ...          ...          ...  \n",
       "128   0.327531          0.0     0.121308  \n",
       "129   0.407922          0.0     0.187346  \n",
       "130   0.697591          0.0     0.484688  \n",
       "131   2.293613          0.0     0.791003  \n",
       "132   1.205300          0.0     0.421807  \n",
       "\n",
       "[133 rows x 21 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate crop + struct attributes combined dataset.\n",
    "def generate_struct_crop_df(year:int) -> pd.DataFrame:\n",
    "    crops_pca = crop_pca()\n",
    "    selectedAttributesCrops = selectTopAtttributesForYear(crops_pca)\n",
    "    selectedAttributesCropsWithYear = [0]*len(selectedAttributesCrops)\n",
    "\n",
    "    for i in range(len(selectedAttributesCrops)):\n",
    "        selectedAttributesCropsWithYear[i] = f\"{selectedAttributesCrops[i]}{year}\"\n",
    "\n",
    "    for key in crops_pca.keys():\n",
    "        if year == int(key.split(\"_\")[-1]):\n",
    "            # attributes = select_top_attr(crops_pca, key)\n",
    "            path = os.path.join(directory, \"data\", \"raw_datasets\", \"structural_attributes\", \"crop_inventories\", f\"{key}.csv\")\n",
    "            attr_file = pd.read_csv(path)\n",
    "            attr_file = attr_file[selectedAttributesCropsWithYear]\n",
    "            attr_file.columns = selectedAttributesCrops\n",
    "\n",
    "            output_df = pd.concat([generate_struct_df(), attr_file], axis=1)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    return output_df\n",
    "\n",
    "generate_struct_crop_df(2012)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature engineer (functional attributes - riverflow metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['YR-RBI-', 'NGM-RBI-', 'Specific-GM-MedianFlow-', 'Specific-NGM-MedianFlow-', 'YR-CVQ-', 'Specific-YR-MedianFlow-', 'Specific-GM-Q95-']\n"
     ]
    }
   ],
   "source": [
    "# metrics to drop.\n",
    "drop_metrics = [\n",
    "    \"Station Name\",\n",
    "    \"Country\",\n",
    "    \"Watershed-Area\",\n",
    "    \"Latitude\",\n",
    "    \"Longitude\",\n",
    "    \"YR-MaxFlow\",\n",
    "    \"GM-MaxFlow\",\n",
    "    \"NGM-MaxFlow\",\n",
    "    \"YR-MinFlow\",\n",
    "    \"GM-MinFlow\",\n",
    "    \"NGM-MinFlow\",\n",
    "    \"YR-MedianFlow\",\n",
    "    \"GM-MedianFlow\",\n",
    "    \"NGM-MedianFlow\",\n",
    "    \"YR-Q95Flow\",\n",
    "    \"GM-Q95Flow\",\n",
    "    \"NGM-Q95Flow\",\n",
    "    \"YR-Q5Flow\",\n",
    "    \"GM-Q5Flow\",\n",
    "    \"NGM-Q5Flow\",\n",
    "]\n",
    "\n",
    "def functional_pca(drop_metrics: list = drop_metrics):\n",
    "    functional_path = os.path.join(directory, \"data\", \"raw_datasets\", \"functional_attributes\", \"133_riverflow\")\n",
    "    functional_files = glob.glob(f\"{functional_path}/*.csv\")\n",
    "\n",
    "    all_top_load_dfs, all_top_metrics = [], {}\n",
    "\n",
    "    for file in functional_files:\n",
    "        df = pd.read_csv(file)\n",
    "        df = df.set_index(df.columns[0])\n",
    "\n",
    "        # drop metrics and checking for missing values.\n",
    "        functional_df = df.loc[:, ~df.columns.str.startswith(tuple(drop_metrics))]\n",
    "        functional_df = functional_df.fillna(functional_df.median())\n",
    "\n",
    "        pca_loadings = pca.loadings(functional_df)\n",
    "\n",
    "        explained_var = pca.explained_variance(functional_df)\n",
    "        pc1_val = round(explained_var[\"Explained Variance\"].iloc[1],2)\n",
    "        pc2_val = round(explained_var[\"Explained Variance\"].iloc[2],2)\n",
    "\n",
    "        top_metrics = pca.top_attributes(pca_loadings, 5)\n",
    "        all_top_metrics[file.split(\"/\")[-1].split(\".\")[0]] = top_metrics\n",
    "        new_keys = {'PC1': f'{file.split(\"/\")[-1].split(\".\")[0]}_PC1_{pc1_val}', 'PC2': f'{file.split(\"/\")[-1].split(\".\")[0]}_PC2_{pc2_val}'}\n",
    "        renamed_top_metrics = {new_keys[key]: value for key, value in top_metrics.items()}\n",
    "        yr_top_load_df = pd.DataFrame(renamed_top_metrics)\n",
    "        all_top_load_dfs.append(yr_top_load_df)\n",
    "\n",
    "    # out_put_df = pd.concat(all_top_load_dfs, axis = 1)\n",
    "    # out_put_df =out_put_df.reindex(sorted(out_put_df.columns), axis=1)\n",
    "\n",
    "    return all_top_metrics\n",
    "\n",
    "functionalAttributes = functional_pca()\n",
    "print(selectTopAtttributesForYear(functionalAttributes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AnnualTotalPrcp_', 'AnnualSumOfRainOnSWE_', 'AnnualMaxSWE_', 'AnnualTotalSnowFall_', 'AnnualNumberRainOnSWEdays_']\n"
     ]
    }
   ],
   "source": [
    "# pca for climate indices\n",
    "def climate_pca():\n",
    "    climate_path = os.path.join(directory, \"data\", \"raw_datasets\", \"climate_indices\")\n",
    "    climate_files = glob.glob(f\"{climate_path}/*.csv\")\n",
    "\n",
    "    all_top_load_dfs, all_top_metrics = [], {}\n",
    "\n",
    "    for file in climate_files:\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "        stations_list = pd.read_csv(\n",
    "        os.path.join(\n",
    "                directory, \"data\", \"raw_datasets\", \"structural_attributes\", \"stations_list.csv\"\n",
    "            )\n",
    "        ).stations.tolist()\n",
    "\n",
    "        stations_list = sorted(stations_list)\n",
    "\n",
    "        df.columns.values[0] = \"station_id\"\n",
    "        df['station_id'] = df['station_id'].apply(lambda val: val.lstrip(\"0\") if val.startswith(\"04\") else val)\n",
    "\n",
    "        climate_df = df[df[\"station_id\"].isin(stations_list)]\n",
    "\n",
    "        # sort the climate_df\n",
    "        climate_df = climate_df.sort_values(\"station_id\")\n",
    "        climate_df.index = range(len(climate_df))\n",
    "\n",
    "        climate_df = climate_df.drop(columns=[\"station_id\"])\n",
    "\n",
    "        # drop metrics and checking for missing values.\n",
    "        climatedfNomissingValues = climate_df.fillna(climate_df.median())\n",
    "\n",
    "        pca_loadings = pca.loadings(climatedfNomissingValues)\n",
    "\n",
    "        explained_var = pca.explained_variance(climatedfNomissingValues)\n",
    "        pc1_val = round(explained_var[\"Explained Variance\"].iloc[1],2)\n",
    "        pc2_val = round(explained_var[\"Explained Variance\"].iloc[2],2)\n",
    "\n",
    "        top_metrics = pca.top_attributes(pca_loadings, 5)\n",
    "        all_top_metrics[file.split(\"/\")[-1].split(\".\")[0]] = top_metrics\n",
    "        new_keys = {'PC1': f'{file.split(\"/\")[-1].split(\".\")[0]}_PC1_{pc1_val}', 'PC2': f'{file.split(\"/\")[-1].split(\".\")[0]}_PC2_{pc2_val}'}\n",
    "        renamed_top_metrics = {new_keys[key]: value for key, value in top_metrics.items()}\n",
    "        yr_top_load_df = pd.DataFrame(renamed_top_metrics)\n",
    "        all_top_load_dfs.append(yr_top_load_df)\n",
    "\n",
    "        out_put_df = pd.concat(all_top_load_dfs, axis = 1)\n",
    "        out_put_df =out_put_df.reindex(sorted(out_put_df.columns), axis=1)\n",
    "\n",
    "    return all_top_metrics\n",
    "\n",
    "climateAttributes = climate_pca()\n",
    "print(selectTopAtttributesForYear(climateAttributes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate new dataset for AP classification (riverflows metrics - year and seasonal).\n",
    "def selected_func_metrics() -> dict:\n",
    "    stations_list = pd.read_csv(\n",
    "        os.path.join(\n",
    "            directory, \"data\", \"raw_datasets\", \"structural_attributes\", \"stations_list.csv\"\n",
    "        )\n",
    "    ).stations.tolist()\n",
    "\n",
    "    func_metrics = {}\n",
    "\n",
    "    # riveflow metrics:\n",
    "    functionalAttributes =selectTopAtttributesForYear(functional_pca())\n",
    "    for year in range(2011, 2021):\n",
    "        functionalAttributesWithYear = [functionalAttributes[i] + str(year) for i in range(len(functionalAttributes))]\n",
    "\n",
    "        functional_path = os.path.join(\n",
    "            directory, \"data\", \"raw_datasets\", \"functional_attributes\", \"133_riverflow\", f'{year}.csv'\n",
    "        )\n",
    "        functional_df = pd.read_csv(functional_path)\n",
    "        functional_df = functional_df[functionalAttributesWithYear]\n",
    "        functional_df['station_id'] = stations_list\n",
    "        functional_df = functional_df[[\"station_id\"] + [col for col in functional_df.columns if col != \"station_id\"]]\n",
    "        func_metrics[str(year)] = functional_df\n",
    "        dir = os.path.join(output_dir, \"func\")\n",
    "        functional_df.to_csv(dir +  f\"/{year}_func_metrics.csv\", index=False)\n",
    "\n",
    "    return functional_df\n",
    "\n",
    "selected_func_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate new dataset for AP classification (riverflows metrics - climate indices).\n",
    "def selected_func_climate_attrs() -> pd.DataFrame:\n",
    "    climateAttributes = selectTopAtttributesForYear(climate_pca())\n",
    "\n",
    "    for year in tqdm(range(2011, 2021)):\n",
    "        df = pd.read_csv(\n",
    "            os.path.join(\n",
    "                directory,\n",
    "                \"data\",\n",
    "                \"raw_datasets\",\n",
    "                \"climate_indices\",\n",
    "                f\"climate_indices_{str(year)}.csv\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "        stations_list = pd.read_csv(\n",
    "        os.path.join(\n",
    "                directory, \"data\", \"raw_datasets\", \"structural_attributes\", \"stations_list.csv\"\n",
    "            )\n",
    "        ).stations.tolist()\n",
    "\n",
    "        stations_list = sorted(stations_list)\n",
    "\n",
    "        df.columns.values[0] = \"station_id\"\n",
    "        df['station_id'] = df['station_id'].apply(lambda val: val.lstrip(\"0\") if val.startswith(\"04\") else val)\n",
    "\n",
    "        climate_df = df[df[\"station_id\"].isin(stations_list)]\n",
    "\n",
    "        # sort the climate_df\n",
    "        climate_df = climate_df.sort_values(\"station_id\")\n",
    "        climate_df.index = range(len(climate_df))\n",
    "\n",
    "        climateAttributesWithYear = [climateAttributes[i] + str(year) for i in range(len(climateAttributes))]\n",
    "        climate_df = climate_df[climateAttributesWithYear]\n",
    "\n",
    "        dir = os.path.join(output_dir, \"func\", f\"{year}_func_metrics.csv\")\n",
    "        functional_df = pd.read_csv(dir)\n",
    "\n",
    "        output_df = pd.concat([functional_df, climate_df], axis=1)\n",
    "\n",
    "        output_df = output_df[[\"station_id\"] + [col for col in output_df.columns if col != \"station_id\"]]\n",
    "\n",
    "        output_df.to_csv(os.path.join(output_dir, \"func_climate\", f\"{year}_func_climate_attrs.csv\"), index=False)\n",
    "        output_df.to_csv(\n",
    "            os.path.join(output_dir, \"func_climate\", f\"{year}_func_climate_attrs.csv\")\n",
    "        , index=False)\n",
    "\n",
    "    return output_df\n",
    "\n",
    "selected_func_climate_attrs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 18.76it/s]\n"
     ]
    }
   ],
   "source": [
    "# generate new dataset for AP classification (riverflow metrics + structural attributes + climate indices)\n",
    "stations_list = pd.read_csv(os.path.join( directory, \"data\", \"raw_datasets\", \"structural_attributes\", \"stations_list.csv\")).stations.tolist()\n",
    "\n",
    "stations_list = sorted(stations_list)\n",
    "\n",
    "\n",
    "for year in tqdm(range(2011, 2021)):\n",
    "    df = pd.read_csv(os.path.join(output_dir, \"func_climate\", f\"{year}_func_climate_attrs.csv\"))\n",
    "    output_df = pd.concat([generate_struct_crop_df(year), df], axis=1)\n",
    "    output_df['station_id'] = stations_list\n",
    "    output_df = output_df[[\"station_id\"] + [col for col in output_df.columns if col != \"station_id\"]]\n",
    "    output_df.to_csv(os.path.join(output_dir, \"all_attributes\", f\"{year}_func_struct_climate_attrs.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA TESTING and AP clustering for Flow metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged after 15 iterations.\n",
      "Min Label: 0 Max Label: 16\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# metrics to drop.\n",
    "drop_metrics = [\n",
    "    \"Station Name\",\n",
    "    \"Country\",\n",
    "    \"Watershed-Area\",\n",
    "    \"Latitude\",\n",
    "    \"Longitude\",\n",
    "    \"YR-MaxFlow\",\n",
    "    \"GM-MaxFlow\",\n",
    "    \"NGM-MaxFlow\",\n",
    "    \"YR-MinFlow\",\n",
    "    \"GM-MinFlow\",\n",
    "    \"NGM-MinFlow\",\n",
    "    \"YR-MedianFlow\",\n",
    "    \"GM-MedianFlow\",\n",
    "    \"NGM-MedianFlow\",\n",
    "    \"YR-Q95Flow\",\n",
    "    \"GM-Q95Flow\",\n",
    "    \"NGM-Q95Flow\",\n",
    "    \"YR-Q5Flow\",\n",
    "    \"GM-Q5Flow\",\n",
    "    \"NGM-Q5Flow\",\n",
    "]\n",
    "\n",
    "\n",
    "functional_path = os.path.join(directory, \"data\", \"raw_datasets\", \"functional_attributes\", \"133_riverflow\", \"2011.csv\")\n",
    "functional_df = pd.read_csv(functional_path)\n",
    "functional_df = functional_df.set_index(functional_df.columns[0])\n",
    "functional_df = functional_df.loc[:, ~functional_df.columns.str.startswith(tuple(drop_metrics))]\n",
    "functional_df = functional_df.fillna(functional_df.median())\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_df = scaler.fit_transform(functional_df)\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(scaled_df)\n",
    "\n",
    "principalDf = pd.DataFrame(data = principalComponents, columns = ['PC1', 'PC2'])\n",
    "\n",
    "# explained_variance = pca.explained_variance_ratio_\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "# print(\"Explained Variance Ratio:\", explained_variance_ratio)\n",
    "\n",
    "\n",
    "cumulative_variance_ratio = explained_variance_ratio.cumsum()\n",
    "n_components = len(cumulative_variance_ratio[cumulative_variance_ratio <= 0.95])\n",
    "# print(\"Number of Principal Components to retain 95% variance:\", n_components)\n",
    "\n",
    "\n",
    "# # loadings\n",
    "loadings = pca.components_.T * np.sqrt(pca.explained_variance_)\n",
    "\n",
    "loadings_df = pd.DataFrame(loadings, columns = ['PC1', 'PC2'], index = functional_df.columns)\n",
    "\n",
    "pc1 = loadings_df['PC1']\n",
    "\n",
    "\n",
    "# use th value of pc1 to get the top 5 attributes\n",
    "topLoadingAttributes_pc1 = pc1.abs().sort_values(ascending=False).head(5).index\n",
    "topLoadingAttributes_pc2 = loadings_df['PC2'].abs().sort_values(ascending=False).head(2).index\n",
    "\n",
    "# topLoadingAttributes = list(set(topLoadingAttributes_pc1).union(set(topLoadingAttributes_pc2)))\n",
    "\n",
    "topLoadingAttributes = [\n",
    "        \"YR-RBI-2011\",\n",
    "        \"NGM-RBI-2011\",\n",
    "        \"Specific-GM-MedianFlow-2011\",\n",
    "        \"Specific-NGM-MedianFlow-2011\",\n",
    "        \"YR-CVQ-2011\",\n",
    "        \"Specific-YR-MedianFlow-2011\",\n",
    "        \"Specific-GM-Q95-2011\",\n",
    "        ]\n",
    "\n",
    "\n",
    "resultedTopAttributes_df = functional_df[topLoadingAttributes]\n",
    "\n",
    "# AP\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "model = AffinityPropagation(damping=0.9, verbose=2)\n",
    "\n",
    "# fit the model\n",
    "resultedTopAttributes_df = resultedTopAttributes_df.fillna(resultedTopAttributes_df.median())\n",
    "model.fit(resultedTopAttributes_df)\n",
    "labels = model.labels_\n",
    "\n",
    "ap_res = {}\n",
    "ap_res[functional_path.split(\"/\")[-1].split(\".\")[0]] = list(labels)\n",
    "result = pd.DataFrame(ap_res).set_index(resultedTopAttributes_df.index)\n",
    "\n",
    "# min and max values of the labels\n",
    "print(\"Min Label:\", min(labels), \"Max Label:\", max(labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
