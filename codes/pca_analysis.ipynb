{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pca import PCA_Analysis \n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "from collections import Counter\n",
    "\n",
    "# load .env file and pca class\n",
    "load_dotenv()\n",
    "directory = os.getenv(\"path\")\n",
    "pca = PCA_Analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to count the most frequent attributes:\n",
    "def count_most_freq(df: pd.DataFrame) -> dict:\n",
    "   cleanList = []\n",
    "   for i in df['attrs']:\n",
    "      crop = i.split('2')[0]\n",
    "      cleanList.append(crop)\n",
    "   cleanList\n",
    "\n",
    "   return Counter(cleanList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "structural attributes (Time-invariant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct_path = os.path.join(directory, \"structural_attributes\", \"140_TI_variables\")\n",
    "struct_files = os.listdir(struct_path)\n",
    "struct_files = [file for file in struct_files if file.endswith(\".csv\")]\n",
    "\n",
    "all_top_load_dfs = []\n",
    "\n",
    "for file in struct_files:\n",
    "    attr_type = file.split(\"_\")[1].split(\".\")[0]\n",
    "    input_struct_data = pd.read_csv(os.path.join(struct_path, file))\n",
    "    struct_data = pd.concat([input_struct_data[\"station_id\"], input_struct_data.iloc[:, 4:]], axis = 1)\n",
    "    struct_data = struct_data.set_index(\"station_id\")\n",
    "\n",
    "    data = pca.pca_analysis(struct_data)\n",
    "    loadings = pca.loadings(struct_data)\n",
    "\n",
    "    explained_var = pca.explained_variance(struct_data)\n",
    "    pc1_val = round(explained_var[\"Explained Variance\"].iloc[1],2)\n",
    "    pc2_val = round(explained_var[\"Explained Variance\"].iloc[2],2)\n",
    "\n",
    "    top_attr = pca.top_attributes(loadings, 5)\n",
    "    new_keys = {'PC1': f'{attr_type}_PC1_{pc1_val}', 'PC2': f'{attr_type}_PC2_{pc2_val}'}\n",
    "    renamed_top_attr = {new_keys[key]: value for key, value in top_attr.items()}\n",
    "    top_load_df = pd.DataFrame(renamed_top_attr)\n",
    "    all_top_load_dfs.append(top_load_df)\n",
    "\n",
    "out_put_df = pd.concat(all_top_load_dfs, axis = 1)\n",
    "out_put_df.to_csv(os.path.join(directory, \"pca_results\", \"TI_top_attributes.csv\"), index=False)\n",
    "\n",
    "# plot the explained variance (example)\n",
    "# pca.pca_plot(explained_var)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "crop inventories (Time-variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "crops_path = os.path.join(directory, \"structural_attributes/crop_inventories\")\n",
    "crop_inventories_files = glob.glob(f\"{crops_path}/*.csv\")\n",
    "\n",
    "all_crop_top_load_dfs = []\n",
    "\n",
    "for path in crop_inventories_files:\n",
    "    crop_yr_df = pd.read_csv(path)\n",
    "    crop_yr_df = crop_yr_df.set_index(crop_yr_df.columns[0])\n",
    "\n",
    "    # crop pca analysis\n",
    "    pca_df = pca.pca_analysis(crop_yr_df)\n",
    "    loadings = pca.loadings(crop_yr_df)\n",
    "\n",
    "    explained_var = pca.explained_variance(crop_yr_df)\n",
    "    pc1_val = round(explained_var[\"Explained Variance\"].iloc[1],2)\n",
    "    pc2_val = round(explained_var[\"Explained Variance\"].iloc[2],2)\n",
    "\n",
    "    top_attr = pca.top_attributes(loadings, 5)\n",
    "    new_keys = {'PC1': f'{path.split(\"/\")[-1].split(\".\")[0]}_PC1_{pc1_val}', 'PC2': f'{path.split(\"/\")[-1].split(\".\")[0]}_PC2_{pc2_val}'}\n",
    "    renamed_top_attr = {new_keys[key]: value for key, value in top_attr.items()}\n",
    "    top_load_df = pd.DataFrame(renamed_top_attr)\n",
    "    all_crop_top_load_dfs.append(top_load_df)\n",
    "\n",
    "crop_out_put_df = pd.concat(all_crop_top_load_dfs, axis = 1)\n",
    "crop_out_put_df = crop_out_put_df.reindex(sorted(crop_out_put_df.columns), axis=1)\n",
    "crop_out_put_df.to_csv(os.path.join(directory, \"pca_results\", \"crop_top_attributes.csv\"), index=False)\n",
    "\n",
    "\n",
    "# count the most frequent attributes\n",
    "# most_freq_crop_attr = pd.read_csv(f\"{directory}/count.csv\")\n",
    "# count_most_freq(most_freq_crop_attr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "functional_path = os.path.join(directory, \"functional_attributes/133_riverflow\")\n",
    "functional_files = glob.glob(f\"{functional_path}/*.csv\")\n",
    "\n",
    "yr_func_dict, szn_func_dict = {}, {}\n",
    "yr_all_top_load_dfs, szn_all_top_load_dfs = [], []\n",
    "\n",
    "for file in functional_files:\n",
    "    functional_df = pd.read_csv(file)\n",
    "    functional_df = functional_df.set_index(functional_df.columns[0])\n",
    "\n",
    "    # func year\n",
    "    yr_functional_df = functional_df.loc[:, functional_df.columns.str.contains('YR')]\n",
    "    yr_remove_list = [\"YR-MaxFlow\", \"YR-MinFlow\",\"YR-MedianFlow\",\"YR-Q95Flow\",\"YR-Q5Flow\"]\n",
    "    yr_functional_df = yr_functional_df.loc[:, ~yr_functional_df.columns.str.startswith(tuple(yr_remove_list))]\n",
    "    yr_functional_df = yr_functional_df.fillna(yr_functional_df.median())\n",
    "\n",
    "    # func seasonal\n",
    "    szn_functional_df = functional_df.loc[:, functional_df.columns.str.contains('GM|NGM')]\n",
    "    szn_remove_list = [\"GM-MaxFlow\", \"GM-MinFlow\",\"GM-MedianFlow\",\"GM-Q95Flow\",\"GM-Q5Flow\",\n",
    "                        \"NGM-MaxFlow\", \"NGM-MinFlow\",\"NGM-MedianFlow\",\"NGM-Q95Flow\",\"NGM-Q5Flow\"]\n",
    "    szn_functional_df = szn_functional_df.loc[:, ~szn_functional_df.columns.str.startswith(tuple(szn_remove_list))]\n",
    "    szn_functional_df = szn_functional_df.fillna(szn_functional_df.median())\n",
    "\n",
    "    # func year pca analysis\n",
    "    yr_pca_df = pca.pca_analysis(yr_functional_df)\n",
    "    yr_loadings = pca.loadings(yr_functional_df)\n",
    "\n",
    "    yr_explained_var = pca.explained_variance(yr_functional_df)\n",
    "    yr_pc1_val = round(yr_explained_var[\"Explained Variance\"].iloc[1],2)\n",
    "    yr_pc2_val = round(yr_explained_var[\"Explained Variance\"].iloc[2],2)\n",
    "    \n",
    "    yr_top_attr = pca.top_attributes(yr_loadings, 5)\n",
    "    new_keys = {'PC1': f'{file.split(\"/\")[-1].split(\".\")[0]}_PC1_{yr_pc1_val}', 'PC2': f'{file.split(\"/\")[-1].split(\".\")[0]}_PC2_{yr_pc2_val}'}\n",
    "    renamed_top_attr = {new_keys[key]: value for key, value in yr_top_attr.items()}\n",
    "    yr_top_load_df = pd.DataFrame(renamed_top_attr)\n",
    "    yr_all_top_load_dfs.append(yr_top_load_df)\n",
    "\n",
    "    # func seasonal pca analysis\n",
    "    szn_pca_df = pca.pca_analysis(szn_functional_df)\n",
    "    szn_loadings = pca.loadings(szn_functional_df)\n",
    "\n",
    "    szn_explained_var = pca.explained_variance(szn_functional_df)\n",
    "    szn_pc1_val = round(szn_explained_var[\"Explained Variance\"].iloc[1],2)\n",
    "    szn_pc2_val = round(szn_explained_var[\"Explained Variance\"].iloc[2],2)\n",
    "    \n",
    "    szn_top_attr = pca.top_attributes(szn_loadings, 5)\n",
    "    new_keys = {'PC1': f'{file.split(\"/\")[-1].split(\".\")[0]}_PC1_{szn_pc1_val}', 'PC2': f'{file.split(\"/\")[-1].split(\".\")[0]}_PC2_{szn_pc2_val}'}\n",
    "    renamed_top_attr = {new_keys[key]: value for key, value in szn_top_attr.items()}\n",
    "    szn_top_load_df = pd.DataFrame(renamed_top_attr)\n",
    "    szn_all_top_load_dfs.append(szn_top_load_df)\n",
    "\n",
    "yr_out_put_df = pd.concat(yr_all_top_load_dfs, axis = 1)\n",
    "yr_out_put_df = yr_out_put_df.reindex(sorted(yr_out_put_df.columns), axis=1)\n",
    "yr_out_put_df.to_csv(os.path.join(directory, \"pca_results\", \"yr_func_top_attributes.csv\"), index=False)\n",
    "\n",
    "szn_out_put_df = pd.concat(szn_all_top_load_dfs, axis = 1)\n",
    "szn_out_put_df = szn_out_put_df.reindex(sorted(szn_out_put_df.columns), axis=1)\n",
    "szn_out_put_df.to_csv(os.path.join(directory, \"pca_results\", \"szn_func_top_attributes.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
